{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f41db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
      "Collecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_cluster-1.6.3%2Bpt28cu126-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.6/1.6 MB 29.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-cluster) (1.16.1)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy->torch-cluster) (1.26.4)\n",
      "Installing collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.6.3+pt28cu126\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cu126.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961d0fb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find module 'C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_cluster\\_grid_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_cluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m knn_graph\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 정사각형 모서리\u001b[39;00m\n\u001b[32m      5\u001b[39m x = torch.tensor([[-\u001b[32m1.\u001b[39m, -\u001b[32m1.\u001b[39m], [-\u001b[32m1.\u001b[39m, \u001b[32m1.\u001b[39m], [\u001b[32m1.\u001b[39m, -\u001b[32m1.\u001b[39m], [\u001b[32m1.\u001b[39m, \u001b[32m1.\u001b[39m]])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_cluster\\__init__.py:18\u001b[39m\n\u001b[32m     16\u001b[39m spec = cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_cpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m                       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp.dirname(\u001b[34m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_ops.py:1478\u001b[39m, in \u001b[36m_Ops.load_library\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m   1473\u001b[39m path = _utils_internal.resolve_library_path(path)\n\u001b[32m   1474\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[32m   1475\u001b[39m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[32m   1476\u001b[39m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[32m   1477\u001b[39m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1478\u001b[39m     \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1479\u001b[39m \u001b[38;5;28mself\u001b[39m.loaded_libraries.add(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ctypes\\__init__.py:379\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Could not find module 'C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_cluster\\_grid_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_cluster import knn_graph\n",
    "\n",
    "# 정사각형 모서리\n",
    "x = torch.tensor([[-1., -1.], [-1., 1.], [1., -1.], [1., 1.]])\n",
    "batch = torch.tensor([0, 0, 0, 0])\n",
    "edge_index = knn_graph(x, k=2, batch=batch, loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_index)\n",
    "tensor([[1, 2, 0, 3, 0, 3, 1, 2],\n",
    "        [0, 0, 1, 1, 2, 2, 3, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4536903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1, 2, 0, 3, 0, 3, 1, 2] # 시작 노드\n",
    "#  ↓  ↓  ↓  ↓  ↓  ↓  ↓  ↓\n",
    "# [0, 0, 1, 1, 2, 2, 3, 3] # 타겟 노드\n",
    "\n",
    "# 최단 거리\n",
    "# 노드 (-1,-1) => 노드 (-1, 1) / 노드 (1, -1)\n",
    "# 노드 (-1,1)\n",
    "# 노드 (1,-1)\n",
    "# 노드 (1,1)\n",
    "\n",
    "# SOM과 KNN을 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005e47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
