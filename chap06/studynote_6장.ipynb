{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a35843",
   "metadata": {},
   "source": [
    "# LeNet-5 구현\n",
    "## 구현 설계\n",
    "- 기본 : pandas, scikit-learn, torch, numpy, matplotlib\n",
    "- 라이브러리 선정\n",
    "- 데이터를 불러와야 됨\n",
    "- 간단한 CNN 모델을 작성\n",
    "- 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386b9ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "import pandas as pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df62d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리\n",
    "# imagenet std mean 수치 사용하면 일반적으로는 괜찮다\n",
    "\n",
    "class ImageTransform:\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            \"train\": transforms.Compose([\n",
    "                transforms.Resize((resize, resize)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5), # 학습에만\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            \"val\": transforms.Compose([\n",
    "                transforms.Resize((resize, resize)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            \"test\": transforms.Compose([\n",
    "                transforms.Resize((resize, resize)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c53b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogVsCatDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None, phase=\"train\"):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\") # 흑백도 RGB로 바꿀거야\n",
    "        img_transform = self.transform(img, self.phase)\n",
    "        if \"dog\" in img_path.lower():\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        return img_transform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03180887",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_directory = Path(\"data/catanddog/train/Cat\")\n",
    "dog_directory = Path(\"data/catanddog/train/Dog\")\n",
    "cat_images_filepaths = sorted([str(p) for p in cat_directory.glob(\"*.jpg\")])\n",
    "dog_images_filepaths = sorted([str(p) for p in dog_directory.glob(\"*.jpg\")])\n",
    "images_filepath = cat_images_filepaths + dog_images_filepaths\n",
    "random.shuffle(images_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c719371f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/catanddog/train/Cat')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab77a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\catanddog\\\\train\\\\Cat\\\\0.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\1.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\10.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\11.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\12.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\13.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\14.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\15.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\16.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\17.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\18.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\19.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\2.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\20.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\21.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\22.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\23.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\24.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\25.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\26.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\27.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\28.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\29.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\3.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\30.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\31.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\32.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\33.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\34.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\35.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\36.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\37.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\38.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\39.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\4.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\40.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\41.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\42.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\43.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\44.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\45.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\46.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\47.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\48.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\49.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\5.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\50.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\51.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\52.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\53.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\54.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\55.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\56.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\57.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\58.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\59.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\6.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\60.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\61.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\62.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7539.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7540.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7541.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7542.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7543.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7544.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7545.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7546.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7547.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7548.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7549.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7550.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7551.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7552.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7553.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7554.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7555.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7556.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7557.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7558.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7559.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7560.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7561.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7562.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7563.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7564.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7565.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7566.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7567.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7568.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7569.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7570.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7571.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7572.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7573.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7574.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7575.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7576.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7577.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7578.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7579.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7580.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7581.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7582.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7583.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7584.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7585.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7586.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7587.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7588.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7589.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7590.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7591.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7592.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7593.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7594.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7595.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7596.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7597.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7598.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7599.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7600.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7601.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7602.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7603.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7604.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7605.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7606.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7607.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7608.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7609.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7610.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7611.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7612.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7613.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7614.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7615.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7616.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7617.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7618.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7619.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7620.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7621.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7622.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7623.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7624.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7625.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7626.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7627.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7628.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7629.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7630.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7631.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7632.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7633.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7634.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7635.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7636.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7637.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7638.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7639.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7640.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7641.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7642.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7643.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7644.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7645.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7646.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7647.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7648.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7649.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7650.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7651.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7652.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7653.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7654.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7655.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7656.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\7657.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\8.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\9.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12360.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12361.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12362.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12363.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12364.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12365.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12366.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12367.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12368.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12369.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12370.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12371.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12372.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12373.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12374.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12375.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12376.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12377.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12378.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12379.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12380.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12381.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12382.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12383.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12384.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12385.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12386.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12387.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12388.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12389.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12390.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12391.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12392.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12393.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12394.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12395.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12396.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12397.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12398.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12399.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12400.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12401.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12402.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12403.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12404.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12405.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12406.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.12407.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8940.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8941.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8942.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8943.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8944.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8945.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8946.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8947.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8948.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8949.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8950.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8951.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8952.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8953.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8954.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8955.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8956.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8957.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8958.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8959.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8960.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8961.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8962.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8963.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8964.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8965.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8966.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8967.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8968.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8969.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8970.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8971.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8972.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8973.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8974.jpg',\n",
       " 'data\\\\catanddog\\\\train\\\\Cat\\\\cat.8975.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cat_directory.glob(\"*.jpg\") -> cat_directory의 .jpg를 포함한 모든것을 잡아라glob\n",
    "[str(p) for p in cat_directory.glob(\"*.jpg\")] # \\\\ -> 이스케이프문자+\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b175725",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = len(images_filepath)\n",
    "train_size = int(total_images * 0.7)\n",
    "val_size = int(total_images * 0.2)\n",
    "test_size = total_images - (train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173c49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filepaths = images_filepath[:train_size]\n",
    "val_images_filepaths = images_filepath[train_size: train_size + val_size]\n",
    "test_images_filepaths = images_filepath[train_size + val_size: train_size + val_size + test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee422e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224,\n",
    "mean= (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9c9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogVsCatDataset(train_images_filepaths, transform=ImageTransform(size, mean, std), phase=\"train\")\n",
    "val_dataset = DogVsCatDataset(val_images_filepaths, transform=ImageTransform(size, mean, std), phase=\"val\")\n",
    "test_dataset = DogVsCatDataset(test_images_filepaths, transform=ImageTransform(size, mean, std), phase=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff40fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0) # shuffle은 train만\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92eb6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dic = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader,\n",
    "    \"test\": test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89c5946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성맵 사이즈 6@28*28(C) -> 6@14*14(Sampling -> Pooling) -> 16@10*10(C) -> 16@5*5 (특성맵 => OOPool)\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 224 -> 220\n",
    "        self.c1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0) \n",
    "        # 220 -> 110\n",
    "        self.s2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        # 110 -> 106\n",
    "        self.c3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        # \n",
    "        self.s4 = nn.AvgPool2d(kernel_size=2, stride=2) # 16*53\n",
    "        #\n",
    "        self.f5 = nn.Linear(53*53*16, 120)\n",
    "        self.f6 = nn.Linear(120, 64)\n",
    "        self.output = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.c1(x)) # 활성화 함수\n",
    "        x = self.s2(x) # 활성화 함수 안한다!!!\n",
    "        x = torch.tanh(self.c3(x))\n",
    "        x = self.s4(x)\n",
    "        \n",
    "        # flatten : CNN -> DNN으로 바꿀 때 flatten 해주기!!!!!\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = torch.tanh(self.f5(x))\n",
    "        x = torch.tanh(self.f6(x))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c883c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (c1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (s2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (c3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (s4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (f5): Linear(in_features=44944, out_features=120, bias=True)\n",
      "  (f6): Linear(in_features=120, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model = LeNet5()\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_dic, criterion, optimizer, num_epoch):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        print(f\"Epoch: {epoch + 1} / {num_epoch}\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            for inputs, labels in tqdm(dataloader_dic[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()                    \n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloader_dic[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader_dic[phase].dataset)            \n",
    "            print(f\"loss: {epoch_loss}, acc: {epoch_acc}\")\n",
    "\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                bst_model_wts = model.state_dict() # 최적의 매개변수를 저장\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"best acc: {best_acc}, end: {time_elapsed % 60}s\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\bgy_3_12\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m criterion = criterion.to(device)\n\u001b[32m      6\u001b[39m num_epoch = \u001b[32m10\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_dic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, dataloader_dic, criterion, optimizer, num_epoch)\u001b[39m\n\u001b[32m     14\u001b[39m epoch_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     15\u001b[39m epoch_corrects = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_dic\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    634\u001b[39m         \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    635\u001b[39m         \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    674\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    677\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     49\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mDogVsCatDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     11\u001b[39m img_path = \u001b[38;5;28mself\u001b[39m.file_list[index]\n\u001b[32m     12\u001b[39m img = Image.open(img_path).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# 흑백도 RGB로 바꿀거야\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m img_transform = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdog\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m img_path.lower():\n\u001b[32m     15\u001b[39m     label = \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mImageTransform.__call__\u001b[39m\u001b[34m(self, img, phase)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, phase):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_transform\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:354\u001b[39m, in \u001b[36mResize.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m    347\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    348\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    349\u001b[39m \u001b[33;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m \u001b[33;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torchvision\\transforms\\functional.py:467\u001b[39m, in \u001b[36mresize\u001b[39m\u001b[34m(img, size, interpolation, max_size, antialias)\u001b[39m\n\u001b[32m    465\u001b[39m         warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    466\u001b[39m     pil_interpolation = pil_modes_mapping[interpolation]\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F_t.resize(img, size=output_size, interpolation=interpolation.value, antialias=antialias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:250\u001b[39m, in \u001b[36mresize\u001b[39m\u001b[34m(img, size, interpolation)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) == \u001b[32m2\u001b[39m):\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\bgy_3_12\\Lib\\site-packages\\PIL\\Image.py:2356\u001b[39m, in \u001b[36mImage.resize\u001b[39m\u001b[34m(self, size, resample, box, reducing_gap)\u001b[39m\n\u001b[32m   2344\u001b[39m         \u001b[38;5;28mself\u001b[39m = (\n\u001b[32m   2345\u001b[39m             \u001b[38;5;28mself\u001b[39m.reduce(factor, box=reduce_box)\n\u001b[32m   2346\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.reduce)\n\u001b[32m   2347\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m Image.reduce(\u001b[38;5;28mself\u001b[39m, factor, box=reduce_box)\n\u001b[32m   2348\u001b[39m         )\n\u001b[32m   2349\u001b[39m         box = (\n\u001b[32m   2350\u001b[39m             (box[\u001b[32m0\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2351\u001b[39m             (box[\u001b[32m1\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2352\u001b[39m             (box[\u001b[32m2\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2353\u001b[39m             (box[\u001b[32m3\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2354\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "num_epoch = 10\n",
    "model = train_model(model, dataloader_dic, criterion, optimizer, num_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bgy_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
