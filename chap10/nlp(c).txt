# %%
"""
필요한 라이브러리 설치: pip install transformers
"""

import re
import time
import random
from pathlib import Path

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.amp import GradScaler, autocast

from transformers import (
    AutoTokenizer,
    AutoModel,
    get_linear_schedule_with_warmup
)

# 한글 폰트 설정
plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# %%
def load_ratings_data(train_path, test_path):
	pass

def clean_text(text):
    if pd.isna(text):
        return ""

    text = str(text)
    # 특수문자 제거 (한글, 영문, 숫자, 공백만 유지)
    text = re.sub(r'[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9\s]', ' ', text)
    # 연속된 공백을 하나로
    text = re.sub(r'\s+', ' ', text)
    # 앞뒤 공백 제거
    text = text.strip()

    return text

def split_train_val(train_df, val_ratio=0.15, random_state=42):
	pass

# %%
class NLPDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(self.labels[idx], dtype=torch.long)
        }

# %%
# 데이터 경로 설정
train_path = "data/ratings_train.txt"
test_path = "data/ratings_test.txt"
train_df, test_df = load_ratings_data(train_path, test_path)
train_df['document'] = train_df['document'].apply(clean_text)
test_df['document'] = test_df['document'].apply(clean_text)
train_df = train_df[train_df['document'].str.len() > 0].reset_index(drop=True)
test_df = test_df[test_df['document'].str.len() > 0].reset_index(drop=True)
train_data, val_data = split_train_val(train_df, val_ratio=0.15, random_state=42)

tokenizer = AutoTokenizer.from_pretrained(model_name)

max_length = 128
batch_size = 32

train_dataset = NLPDataset(
    train_data['document'].values,
    train_data['label'].values,
    tokenizer,
    max_length
)
val_dataset = NLIDataset(
    val_data['document'].values,
    val_data['label'].values,
    tokenizer,
    max_length
)
test_dataset = NLIDataset(
    test_df['document'].values,
    test_df['label'].values,
    tokenizer,
    max_length
)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)


# %%
class SentimentClassifier(nn.Module):
	pass



# %%
model_name = 'klue/roberta-base'
model = SentimentClassifier(
    model_name=model_name,
    n_classes=2,
    dropout_rate=0.2
)
model = model.to(device)


# %%
def train_model(model, train_loader, val_loader, epochs, lr, patience):
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
    criterion = nn.CrossEntropyLoss()
    total_steps = len(train_loader) * epochs
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=int(0.1 * total_steps),
        num_training_steps=total_steps
    )
    scaler = GradScaler(enabled=(device.type == 'cuda'))

    train_losses, val_accuracies, train_accuracies = [], [], []
    best_val_acc = 0.0
    epochs_no_improve = 0

    for epoch in range(epochs):
        print(f"\nEpoch {epoch + 1}/{epochs}")
        print("-" * 30)

        model.train()
        total_loss, correct_predictions, total_predictions = 0.0, 0, 0
        start_time = time.time()

        for batch_idx, batch in enumerate(train_loader):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            optimizer.zero_grad()

            with autocast(device_type=device.type, enabled=(device.type == 'cuda')):
                outputs = model(input_ids, attention_mask)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            scheduler.step()

            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total_predictions += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()

            if (batch_idx + 1) % 200 == 0:
                current_acc = 100.0 * correct_predictions / total_predictions
                current_loss = total_loss / (batch_idx + 1)
                print(f"  Batch {batch_idx + 1:4d}: Loss {current_loss:.4f}, Acc {current_acc:.2f}%")

        epoch_time = time.time() - start_time
        train_acc = 100.0 * correct_predictions / total_predictions
        avg_loss = total_loss / len(train_loader)
        val_acc = validate_model(model, val_loader) # 검증

        train_losses.append(avg_loss)
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)

        print(f"\nResult:")
        print(f"  Train Loss: {avg_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"  Val Acc: {val_acc:.2f}%")
        print(f"  Time: {epoch_time:.1f}s, Learning Rate: {scheduler.get_last_lr()[0]:.2e}")

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), 'best_model.pth')
            print(f"  ✓ Best model saved (Val Acc: {best_val_acc:.2f}%)")
            epochs_no_improve = 0
        else:
            epochs_no_improve += 1
            print(f"  ! No improvement. (Patience: {epochs_no_improve}/{patience})")

        if epochs_no_improve >= patience:
            print(f"\n{patience} epochs without improvement. Early stopping.")
            break

    print(f"\nTrain complete! Best val accuracy: {best_val_acc:.2f}%")
    return train_losses, val_accuracies, train_accuracies

def validate_model(model, val_loader):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            with autocast(device_type=device.type, enabled=(device.type == 'cuda')):
                outputs = model(input_ids, attention_mask)

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return 100.0 * correct / total

# %%
train_losses, val_accuracies, train_accuracies = train_model(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    epochs=5,
    lr=3e-5,
    patience=2
)

# %%
def plot_training_history(train_losses, val_accuracies, train_accuracies):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    epochs_ran = len(train_losses)
    x_axis = range(1, epochs_ran + 1)

    ax1.plot(x_axis, train_losses, 'b-o', label='Train Loss', linewidth=2)
    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_xticks(x_axis)

    ax2.plot(x_axis, train_accuracies, 'b-o', label='Train Accuracy', linewidth=2)
    ax2.plot(x_axis, val_accuracies, 'r-o', label='Validation Accuracy', linewidth=2)
    ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_xticks(x_axis)

    plt.tight_layout()
    plt.show()

plot_training_history(train_losses, val_accuracies, train_accuracies)

# %%
def evaluate_model(model, test_loader):
    model.eval()
    all_predictions, all_labels = [], []
    with torch.no_grad():
        for batch in test_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            with autocast(device_type=device.type, enabled=(device.type == 'cuda')):
                outputs = model(input_ids, attention_mask)

            _, predicted = torch.max(outputs, 1)
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    return all_predictions, all_labels

def print_detailed_results(predictions, labels):
    accuracy = np.mean(np.array(predictions) == np.array(labels))
    print("\n" + "="*50)
    print("Final evaluation results")
    print("="*50)
    print(f"\n전체 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)")

    cm = confusion_matrix(labels, predictions)
    print(f"\nConfusion Matrix:")
    print(f"               예측")
    print(f"Actual     Negative(0)   Positive(1)")
    print(f"Negative(0)   {cm[0,0]:5d}   {cm[0,1]:5d}")
    print(f"Positive(1)   {cm[1,0]:5d}   {cm[1,1]:5d}")

    print(f"\nDetailed performance indicators:")
    print(classification_report(labels, predictions, target_names=['Negative', 'Positive'], digits=4))

print("\nTesting with the best model...")
model.load_state_dict(torch.load('best_model.pth'))
predictions, labels = evaluate_model(model, test_loader)
print_detailed_results(predictions, labels)

# %%
def predict_sentiment(model, tokenizer, text, max_length=128):
    model.eval()
    cleaned_text = clean_text(text)
    encoding = tokenizer(
        cleaned_text,
        truncation=True,
        padding='max_length',
        max_length=max_length,
        return_tensors='pt'
    )

    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)

    with torch.no_grad():
        with autocast(device_type=device.type, enabled=(device.type == 'cuda')):
            outputs = model(input_ids, attention_mask)
        probabilities = torch.softmax(outputs, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0][predicted_class].item()

    sentiment = "Positive" if predicted_class == 1 else "Negative"
    return sentiment, confidence

sample_texts = [
    "이 영화는 정말 재미있고 감동적이었습니다!",
    "완전 실망스러운 영화였어요. 시간 낭비...",
    "배우들의 연기가 훌륭했고 스토리도 좋았습니다.",
    "지루하고 뻔한 내용이라 보는 내내 졸았어요",
    "평범한 영화입니다. 그냥 그래요."
]

for i, text in enumerate(sample_texts, 1):
    sentiment, confidence = predict_sentiment(model, tokenizer, text)
    print(f"{i}. Text: {text}")
    print(f"   Prediction: {sentiment} (Confidence: {confidence:.4f})")
    print()
